{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, AveragePooling2D, concatenate\n",
    "from keras.layers import GRU, BatchNormalization, Reshape\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Conv1D, Activation, MaxPool1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../cache/dataset.pkl.gz', 'rb') as f:\n",
    "    X_raw, y_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds = [4, 8, 11, 12, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../annotations/cursach2.TextGrid',\n",
       " '../annotations/gomes.TextGrid',\n",
       " '../annotations/olya1.TextGrid',\n",
       " '../annotations/olya2.TextGrid',\n",
       " '../annotations/vika1.TextGrid']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['../annotations/cursach2.TextGrid',\n",
    " '../annotations/gomes.TextGrid',\n",
    " '../annotations/olya1.TextGrid',\n",
    " '../annotations/olya2.TextGrid',\n",
    " '../annotations/vika1.TextGrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def extract_features(x, lim=100):\n",
    "    _, _, spec = log_specgram(x, sample_rate)\n",
    "    spec = spec[:, :lim]\n",
    "    spec = np.expand_dims(spec, -1)\n",
    "    return spec\n",
    "\n",
    "input_shape = (28, 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_crossval(X_raw_, y_raw_, folds_inds, model_create, schedule, epochs):\n",
    "    X_raw = X_raw_.copy()\n",
    "    y_raw = y_raw_.copy()\n",
    "    folds_results = []\n",
    "    \n",
    "    for fold in folds_inds:\n",
    "        print('Fold:', fold)\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "        for i, x in enumerate(X_raw):\n",
    "            if i != fold:\n",
    "                X_train.extend(x)\n",
    "\n",
    "        for i, y in enumerate(y_raw):\n",
    "            if i != fold:\n",
    "                y_train.extend(y)\n",
    "        \n",
    "        X_test = X_raw[fold]\n",
    "        y_test = y_raw[fold]\n",
    "        \n",
    "        X_train = [x if type(x) == type(np.array([])) else np.array(x) for x in X_train]\n",
    "        X_test = [x if type(x) == type(np.array([])) else np.array(x) for x in X_test]\n",
    "\n",
    "        bad_inds = (np.array([len(x) != 6615 for x in X_train])).nonzero()[0]\n",
    "        if len(bad_inds) != 0:\n",
    "            X_train = np.delete(X_train, bad_inds)\n",
    "            y_train = np.delete(y_train, bad_inds)\n",
    "    \n",
    "        bad_inds = (np.array([len(x) != 6615 for x in X_test])).nonzero()[0]\n",
    "        if len(bad_inds) != 0:\n",
    "            X_test = np.delete(X_test, bad_inds)\n",
    "            y_test = np.delete(y_test, bad_inds)\n",
    "        \n",
    "        X_spec_train = []\n",
    "        for x in X_train:\n",
    "            spec = extract_features(x)\n",
    "            X_spec_train.append(spec)\n",
    "        X_spec_train = np.array(X_spec_train)\n",
    "\n",
    "        X_spec_test = []\n",
    "        for x in X_test:\n",
    "            spec = extract_features(x)\n",
    "            X_spec_test.append(spec)\n",
    "        X_spec_test = np.array(X_spec_test)\n",
    "        \n",
    "        mean = X_spec_train.mean()\n",
    "        std = X_spec_train.std()\n",
    "        \n",
    "        X_spec_train -= mean\n",
    "        X_spec_train /= std\n",
    "        X_spec_test -= mean\n",
    "        X_spec_test /= std\n",
    "        \n",
    "        y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "        \n",
    "        X_spec_train = np.vstack((X_spec_train, np.repeat(X_spec_train[np.argmax(y_train, 1) == 0], 4, 0)))\n",
    "        y_train = np.vstack((y_train, np.repeat(y_train[np.argmax(y_train, 1) == 0], 4, 0)))\n",
    "\n",
    "        X_spec_train = np.vstack((X_spec_train, np.repeat(X_spec_train[np.argmax(y_train, 1) == 1], 20, 0)))\n",
    "        y_train = np.vstack((y_train, np.repeat(y_train[np.argmax(y_train, 1) == 1], 20, 0)))\n",
    "        \n",
    "        print('Train on:', X_train.shape)       \n",
    "        model = model_create(input_shape)\n",
    "        model.compile('adam', 'categorical_crossentropy')\n",
    "        \n",
    "        model.fit(X_spec_train, y_train, batch_size=64, epochs=epochs,\n",
    "                 callbacks=[keras.callbacks.LearningRateScheduler(schedule, verbose=0)],\n",
    "                 verbose=0)\n",
    "        pr = model.predict(X_spec_test, batch_size=64, verbose=0)\n",
    "        pr = pr.argmax(1)\n",
    "        \n",
    "        acc = accuracy_score(np.argmax(y_test, 1), pr)\n",
    "        cl_rep = classification_report(np.argmax(y_test, 1), pr)\n",
    "        f1_micro = f1_score(np.argmax(y_test, 1), pr, average='micro')\n",
    "        f1_macro = f1_score(np.argmax(y_test, 1), pr, average='macro')\n",
    "        \n",
    "        folds_results.append((fold, acc, cl_rep, f1_micro, f1_macro))\n",
    "    return folds_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape):\n",
    "    x_input = Input(input_shape)\n",
    "    x = Reshape(input_shape[:-1])(x_input)\n",
    "\n",
    "    x = Conv1D(128, 3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GRU(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = GRU(192, return_sequences=False)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    model = Model(inputs=x_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def schedule(i, lr):\n",
    "    if i == 0:\n",
    "        lr *= 0.5\n",
    "    if i == 5:\n",
    "        lr *= 0.2\n",
    "    if i == 10:\n",
    "        lr *= 0.2\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4\n",
      "Train on: (17409,)\n",
      "Fold: 8\n",
      "Train on: (17140,)\n",
      "Fold: 11\n",
      "Train on: (18467,)\n",
      "Fold: 12\n",
      "Train on: (18306,)\n",
      "Fold: 15\n",
      "Train on: (18544,)\n"
     ]
    }
   ],
   "source": [
    "rnn_res = make_crossval(X_raw, y_raw, test_folds, create_rnn_model, schedule, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in res:\n",
    "    print(r[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    x_input = Input(input_shape)\n",
    "    x = Conv2D(16, 3, activation='relu', padding='same')(x_input)\n",
    "    x = Conv2D(16, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D((2, 3))(x)\n",
    "    \n",
    "    x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Conv2D(128, 3, activation='relu')(x)\n",
    "    x = Conv2D(128, (1, 6), activation='relu')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def schedule(i, lr):\n",
    "    if i == 0:\n",
    "        lr *= 0.5\n",
    "    if i == 5:\n",
    "        lr *= 0.2\n",
    "    if i == 10:\n",
    "        lr *= 0.2\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4\n",
      "Train on: (17409,)\n",
      "Fold: 8\n",
      "Train on: (17140,)\n",
      "Fold: 11\n",
      "Train on: (18467,)\n",
      "Fold: 12\n",
      "Train on: (18306,)\n",
      "Fold: 15\n",
      "Train on: (18544,)\n"
     ]
    }
   ],
   "source": [
    "cnn_res = make_crossval(X_raw, y_raw, test_folds, create_cnn_model, schedule, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_twin_model(input_shape):\n",
    "    x_input = Input(input_shape)\n",
    "    \n",
    "    # Cnn part\n",
    "    c = Conv2D(16, 3, activation='relu', padding='same')(x_input)\n",
    "    c = Conv2D(16, 3, activation='relu', padding='same')(c)\n",
    "    c = MaxPool2D((2, 3))(c)\n",
    "    \n",
    "    c = Conv2D(16, 3, activation='relu', padding='same')(c)\n",
    "    c = Conv2D(32, 3, activation='relu', padding='same')(c)\n",
    "    c = MaxPool2D()(c)\n",
    "\n",
    "    c = Conv2D(32, 3, activation='relu', padding='same')(c)\n",
    "    c = Conv2D(64, 3, activation='relu', padding='same')(c)\n",
    "    c = MaxPool2D()(c)\n",
    "    \n",
    "    c = Conv2D(64, 3, activation='relu')(c)\n",
    "    c = Conv2D(128, (1, 6), activation='relu')(c)\n",
    "    c = Reshape((int(c.shape[-1:][0]),))(c)\n",
    "    c = Dropout(0.5)(c)\n",
    "    \n",
    "    # Rnn part\n",
    "    r = Reshape(input_shape[:-1])(x_input)\n",
    "    r = Conv1D(96, 3)(r)\n",
    "    r = BatchNormalization()(r)\n",
    "    r = Activation('relu')(r)\n",
    "    r = Dropout(0.5)(r)\n",
    "    \n",
    "    r = GRU(96, return_sequences=True)(r)\n",
    "    r = Dropout(0.5)(r)\n",
    "    r = BatchNormalization()(r)\n",
    "    \n",
    "    r = GRU(64, return_sequences=False)(r)\n",
    "    r = Dropout(0.5)(r)\n",
    "    r = BatchNormalization()(r)\n",
    "    \n",
    "    x = concatenate([c, r])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def schedule(i, lr):\n",
    "    if i == 0:\n",
    "        lr *= 0.5\n",
    "    if i == 5:\n",
    "        lr *= 0.2\n",
    "    if i == 10:\n",
    "        lr *= 0.2\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 4\n",
      "Train on: (17409,)\n",
      "Fold: 8\n",
      "Train on: (17140,)\n",
      "Fold: 11\n",
      "Train on: (18467,)\n",
      "Fold: 12\n",
      "Train on: (18306,)\n",
      "Fold: 15\n",
      "Train on: (18544,)\n"
     ]
    }
   ],
   "source": [
    "twin_res = make_crossval(X_raw, y_raw, test_folds, create_twin_model, schedule, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cache/res_cv.pkl', 'wb') as f:\n",
    "    pickle.dump((rnn_res, cnn_res, twin_res), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7379842711614976, 0.0605726739209234)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([r[4] for r in rnn_res]), np.std([r[4] for r in rnn_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7337921415450412, 0.07011895338751599)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([r[4] for r in cnn_res]), np.std([r[4] for r in cnn_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7457619903189693, 0.03550755319676306)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([r[4] for r in twin_res]), np.std([r[4] for r in twin_res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.901249473158801, 0.03088177766784812)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([r[1] for r in rnn_res]), np.std([r[1] for r in rnn_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.929114432334256, 0.0308061627976787)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([r[1] for r in cnn_res]), np.std([r[1] for r in cnn_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9264118970437825, 0.022688938801155446)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([r[1] for r in twin_res]), np.std([r[1] for r in twin_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cache/res_cv.pkl', 'rb') as f:\n",
    "    rnn_res, cnn_res, twin_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
