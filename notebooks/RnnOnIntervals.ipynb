{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../cache/dataset.pkl.gz', 'rb') as f:\n",
    "    X_raw, y_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_raw), len(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout, y_holdout = X_raw[10], y_raw[10] # lavina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = X_raw[:10] + X_raw[11:]\n",
    "y_raw = y_raw[:10] + y_raw[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for x in X_raw:\n",
    "    X.extend(x)\n",
    "\n",
    "for y_ in y_raw:\n",
    "    y.extend(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x for x, y_ in zip(X, y) if y_ == 0]\n",
    "b = [x for x, y_ in zip(X, y) if y_ == 1]\n",
    "c = [x for x, y_ in zip(X, y) if y_ == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [np.array(x) for x in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a), len(b), len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wids = [Audio(a[i], rate=22050) for i in np.random.randint(0, len(a), 3)]\n",
    "\n",
    "for w in wids:\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wids = [Audio(b[i], rate=22050) for i in np.random.randint(0, len(b), 3)]\n",
    "\n",
    "for w in wids:\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wids = [Audio(c[i], rate=22050) for i in np.random.randint(0, len(c), 3)]\n",
    "\n",
    "for w in wids:\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = c[666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "freqs, times, spectrogram = log_specgram(samples, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, times, spectrogram = log_specgram(samples, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw wave')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, len(samples) / sample_rate, len(samples)), samples)\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "ax2.set_yticks(freqs[::16])\n",
    "ax2.set_xticks(times[::16])\n",
    "ax2.set_title('Spectrogram')\n",
    "ax2.set_ylabel('Freqs in Hz')\n",
    "ax2.set_xlabel('Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://librosa.github.io/librosa/generated/librosa.core.resample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "samples_r = librosa.resample(samples, sample_rate, new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "freqs, times, spectrogram = log_specgram(samples_r, new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, times, spectrogram = log_specgram(samples_r, new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw wave')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, len(samples_r) / 8000, len(samples_r)), samples_r)\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "ax2.set_yticks(freqs[::16])\n",
    "ax2.set_xticks(times[::16])\n",
    "ax2.set_title('Spectrogram')\n",
    "ax2.set_ylabel('Freqs in Hz')\n",
    "ax2.set_xlabel('Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(samples_r, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this tutorial\n",
    "# https://github.com/librosa/librosa/blob/master/examples/LibROSA%20demo.ipynb\n",
    "S = librosa.feature.melspectrogram(samples, sr=sample_rate, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "plt.title('Mel power spectrogram ')\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "\n",
    "# Let's pad on the first and second deltas while we're at it\n",
    "delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(delta2_mfcc)\n",
    "plt.ylabel('MFCC coeffs')\n",
    "plt.xlabel('Time')\n",
    "plt.title('MFCC')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(fft(samples))[:len(samples)//2])\n",
    "# plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fft(y, fs):\n",
    "#     T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "#     xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "#     vals = 2.0/N * np.abs(yf[0:N//2]) \n",
    "#     FFT is also complex, to we take just the real part (abs)\n",
    "    vals = np.abs(yf[0:N//2])\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before and after resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(samples_r, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = custom_fft(samples, sample_rate)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('FFT of recording sampled with ' + str(sample_rate) + ' Hz')\n",
    "plt.plot(range(len(vals)), vals)\n",
    "plt.xlabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = custom_fft(samples_r, new_sample_rate)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('FFT of recording sampled with ' + str(new_sample_rate) + ' Hz')\n",
    "plt.plot(range(len(vals)), vals)\n",
    "plt.xlabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = custom_fft(samples, sample_rate)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('FFT of recording sampled with ' + str(sample_rate) + ' Hz')\n",
    "plt.plot(range(len(vals)), vals)\n",
    "plt.xlabel('Frequency')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, aa in enumerate(a[:3]):\n",
    "    vals = custom_fft(aa, new_sample_rate)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.title('FFT of {}'.format(i))\n",
    "    plt.plot(range(len(vals)), vals)\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a[0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a[1], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(a[2], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extratction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x if type(x) == type(np.array([])) else np.array(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout = [x if type(x) == type(np.array([])) else np.array(x) for x in X_holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ind = (np.array([len(x) == 6318 for x in X])).nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:bad_ind] + X[bad_ind + 1:]\n",
    "y = y[:bad_ind] + y[bad_ind + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, s = log_specgram(a[1], sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(s[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x, lim=100):\n",
    "    _, _, spec = log_specgram(x, sample_rate)\n",
    "#     return np.expand_dims(spec[:, :100], -1)\n",
    "    return spec[:, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec = []\n",
    "for x in tqdm(X):\n",
    "    spec = extract_features(x)\n",
    "    X_spec.append(spec)\n",
    "X_spec = np.array(X_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout_spec = []\n",
    "for x in tqdm(X_holdout):\n",
    "    spec = extract_features(x)\n",
    "    X_holdout_spec.append(spec)\n",
    "X_holdout_spec = np.array(X_holdout_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking mean specs for different audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_raw_specs = []\n",
    "# for raw in tqdm(X_raw):\n",
    "#     specs = []\n",
    "#     for sample in raw:\n",
    "#         spec = extract_features(np.array(sample))\n",
    "#         if spec.shape == (28, 100):\n",
    "#             specs.append(spec)\n",
    "#     specs = np.array(specs)\n",
    "#     X_raw_specs.append(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(X_raw_specs)):\n",
    "# #     print(X_raw_specs[i].shape)\n",
    "#     print(X_raw_specs[i].mean(), X_raw_specs[i].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, AveragePooling2D\n",
    "from keras.layers import GRU, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Conv1D, Activation, MaxPool1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_spec.mean()\n",
    "std = X_spec.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_spec, max_spec = X_spec.min(), X_spec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_spec, max_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_spec.ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_spec.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_spec.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_spec.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_spec -= mean\n",
    "# X_spec /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec -= min_spec\n",
    "X_spec /= (max_spec - min_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.mean(), X_spec.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spec.min(), X_spec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_spec, y, test_size=0.1,\n",
    "                                                    stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1,\n",
    "#                                                     stratify=y_train, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = X_holdout_spec, y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val -= mean\n",
    "# X_val /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val -= min_spec\n",
    "X_val /= (max_spec - min_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.mean(), X_val.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.min(), X_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val, y_test = to_categorical(y_train), to_categorical(y_val),\\\n",
    "                         to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.Series.value_counts(np.argmax(y_train, 1), True)\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.Series.value_counts(np.argmax(y_val, 1), True)\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.Series.value_counts(np.argmax(y_test, 1), True)\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc[2] / vc[0] * frac - 1, vc[2] / vc[1] * frac - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train, np.repeat(X_train[np.argmax(y_train, 1) == 0], 4, 0)))\n",
    "y_train = np.vstack((y_train, np.repeat(y_train[np.argmax(y_train, 1) == 0], 4, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((X_train, np.repeat(X_train[np.argmax(y_train, 1) == 1], 20, 0)))\n",
    "y_train = np.vstack((y_train, np.repeat(y_train[np.argmax(y_train, 1) == 1], 20, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(np.argmax(y_train, 1), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    x_input = Input(input_shape)\n",
    "#     x = Conv1D(64, 1)(x_input)\n",
    "#     x = Activation('relu')(x)\n",
    "    x = Conv1D(128, 3)(x_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = GRU(128, return_sequences=True)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = GRU(192, return_sequences=False)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "    model = Model(inputs=x_input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(model.predict(X_train[:1])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(np.array(X_val), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[:10].argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pr.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_val, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_val, 1), pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(np.argmax(y_test, 1), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(i, lr):\n",
    "    if i == 0:\n",
    "        lr *= 0.5\n",
    "    if i == 5:\n",
    "        lr *= 0.2\n",
    "    if i == 10:\n",
    "        lr *= 0.2\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def schedule(i, lr):\n",
    "#     if i == 0:\n",
    "#         lr = 0.0005\n",
    "#     if i == 5:\n",
    "#         lr *= 0.2\n",
    "#     if i == 10:\n",
    "#         lr *= 0.2\n",
    "#     return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64, epochs=10,\n",
    "#                  class_weight={0: 3, 1: 5, 2: 1},\n",
    "                 validation_data=(X_test, y_test), # val\n",
    "                 callbacks=[keras.callbacks.LearningRateScheduler(schedule, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../cache/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../cache/model2.json', 'w') as f:\n",
    "    f.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('../cache/model2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(X_val, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr = pr.ravel()\n",
    "pr = pr.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_val, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_val, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_val, 1), pr)) # :100 standart fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_val, 1), pr)) # :100 standart fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(X_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr = pr.ravel()\n",
    "pr = pr.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_test, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_test, 1), pr)) # :100 standart fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_test, 1), pr)) # :100 standart fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time model.predict(X_val[:1, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model.predict(X_val[:1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(y_test, 1), bins=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pr, bins=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_test, 1), [2] * len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.get_weights()[0][:, :, 2])\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(X_test, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr = pr.ravel()\n",
    "pr = pr.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(y_test, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test, 1), pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(y_test, 1), pr)) # :100 standart fcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_praat_annotations(paths):\n",
    "    dfs = []\n",
    "    for path in paths:\n",
    "        with open(path) as f:\n",
    "            annotation = [l.strip() for l in f.readlines()]\n",
    "            \n",
    "        indxs = [i for i, l in enumerate(annotation) if l == '\"IntervalTier\"']\n",
    "        annotation = annotation[indxs[0] + 5:indxs[1] if len(indxs) > 1\\\n",
    "                                else len(annotation)]\n",
    "        annotation_dicts = []\n",
    "\n",
    "        for s, e, l in zip(annotation[0::3], annotation[1::3], annotation[2::3]):\n",
    "            annotation_dicts.append({\n",
    "                'start': float(s),\n",
    "                'finish': float(e),\n",
    "                'label': l.replace('\"', ''),\n",
    "                'length': float(e) - float(s)\n",
    "            })\n",
    "        df = pd.DataFrame(annotation_dicts)\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "test_annotation = get_praat_annotations(['../annotations/lavina_class.TextGrid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio, sr = librosa.load('../audio/lavina_class.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_time = 0.3\n",
    "interval_step = 0.1\n",
    "\n",
    "interval_len, step_len = librosa.time_to_samples(interval_time), \\\n",
    "                 librosa.time_to_samples(interval_step) #[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_len, step_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_annotation[0][test_annotation[0].label == 'a'].length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.time_to_samples(0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersection_of_intervals(a, b):\n",
    "    # a - fixed, b - random, a[0] - x1, a[1] - y1\n",
    "    int_len = a[1] - a[0]\n",
    "    \n",
    "    if b[1] > a[0]:\n",
    "        right_int = max(a[1] - b[1], 0)\n",
    "    else:\n",
    "        right_int = int_len\n",
    "    \n",
    "    if b[0] < a[1]:\n",
    "        left_int = max(b[0] - a[0], 0)\n",
    "    else:\n",
    "        left_int = int_len\n",
    "    return int_len - right_int - left_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_delta = interval_len // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_intervals(annotation, audio, labels, sr=22050):\n",
    "    audio_intervals = [(x, x + interval_len) for x in range(0, len(audio), step_len)][:-4]\n",
    "    targets = []\n",
    "    values = []\n",
    "    label_map = {'a': 0, 'b': 1, 'c': 2}\n",
    "    for interval in audio_intervals:\n",
    "        value = 0\n",
    "        for label in labels:\n",
    "            l = label_map[label]\n",
    "            start_samples_indxs = librosa.time_to_samples(annotation[annotation.label ==\\\n",
    "                                                                  label].start.values, sr)\n",
    "            finish_samples_indxs = librosa.time_to_samples(annotation[annotation.label ==\\\n",
    "                                                                   label].finish.values,\n",
    "                                                                   sr)\n",
    "            for s, f in zip(start_samples_indxs, finish_samples_indxs):\n",
    "                value = get_intersection_of_intervals(interval, (s, f))\n",
    "                if value > min_delta:\n",
    "                    break\n",
    "                else:\n",
    "                    value = 0\n",
    "            if value != 0:\n",
    "                break\n",
    "        if value != 0:\n",
    "            targets.append(l)\n",
    "        else:\n",
    "            targets.append(2)\n",
    "        values.append(value)\n",
    "    return audio_intervals, targets, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идем с шагом step_len и берем интервалы по interval_len, проверяем - с каким из размеченных интервалов пересекается наш интервал больше чем на min_delta и присваиваем его метку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не учитываются случаи, когда идет несколько подряд \"эээ\" и \"нуу\", и так как метки отсортированы, пока интервал будет касаться левой стороной первого \"эээ\", а правой \"нуу\", то будет присвоена метка \"эээ\". **TODO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_intervals, test_targets, vals = match_intervals(test_annotation[0], test_audio,\n",
    "                                                     ['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_intervals), len(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_targets[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_label_data(annotation, audio, labels, sr=22050):\n",
    "#     # по дефолту все 2го класса\n",
    "#     data = pd.Series(index=np.arange(0, len(audio) - interval_len, step_len), data=2)\n",
    "#     label_map = {'a': 0, 'b': 1, 'c': 2}\n",
    "#     for label in labels:\n",
    "#         l = label_map[label]\n",
    "#         start_samples_indxs = librosa.time_to_samples(annotation[annotation.label ==\\\n",
    "#                                                               label].start.values, sr)\n",
    "#         finish_samples_indxs = librosa.time_to_samples(annotation[annotation.label ==\\\n",
    "#                                                                label].finish.values, sr)\n",
    "#         for s, f in zip(start_samples_indxs, finish_samples_indxs):\n",
    "#             s = int(np.round(s / step_len)) * step_len\n",
    "#             f = (int(np.round(f / step_len)) - 2) * step_len\n",
    "#             # вычитаем 2 потому что f - это конец интервала, в Series мы заносим метку для \n",
    "#             # начала  интервала, длина интервала 2 * step, поэтому нужно вычесть 2\n",
    "#             data[(data.index >= s) & (data.index <= f)] = l\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = [test_audio[s:f] for s, f in test_intervals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = [(t1, t2) for t1, t2 in zip(test_samples, vals) if t2 !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(filter(lambda x: x!=0, vals))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(t1[9][0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.stack([extract_features(x) for x in tqdm(test_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: нормальная нормальзация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-20.350365, 2.89434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_features -= -20.350365\n",
    "# test_features /= 2.89434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features -= min_spec\n",
    "test_features /= (max_spec - min_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.min(), test_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(test_features, batch_size=32).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_pr = model.predict(test_features, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** сделать усреднение предикта с 1 влево 1 вправо интервалами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_targets, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_targets, [2] * len(test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(test_targets, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_targets, test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_predict[:2000], '--', label='pr', alpha=0.4)\n",
    "plt.plot(test_targets[:2000], '-.', label='tr', alpha=0.4)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_mean = np.stack(((np.pad(test_predict_pr[1:, 0], (0, 1), 'edge') + \\\n",
    "                    test_predict_pr[:, 0] + \\\n",
    "    np.pad(test_predict_pr[:-1, 0], (1, 0), 'edge')) / 3,\n",
    "          (np.pad(test_predict_pr[1:, 1], (0, 1), 'edge') + test_predict_pr[:, 1] + \\\n",
    "    np.pad(test_predict_pr[:-1, 1], (1, 0), 'edge')) / 3,\n",
    "          (np.pad(test_predict_pr[1:, 2], (0, 1), 'edge') + test_predict_pr[:, 2] + \\\n",
    "    np.pad(test_predict_pr[:-1, 2], (1, 0), 'edge')) / 3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_predict[:lim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_predict_pr[:lim, 0], label='0')\n",
    "plt.plot(test_predict_pr[:lim, 1], label='1')\n",
    "plt.plot(test_predict_pr[:lim, 2], label='2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_predict_mean[:lim, 0], label='0')\n",
    "plt.plot(test_predict_mean[:lim, 1], label='1')\n",
    "plt.plot(test_predict_mean[:lim, 2], label='2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_mean[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_pr[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_targets, test_predict_pr.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_targets, test_predict_mean.argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_targets, test_predict_pr.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_targets, test_predict_mean.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.nonzero((test_targets != test_predict_pr.argmax(1)) & \\\n",
    "               (test_predict_pr.argmax(1) == 0))[0]\n",
    "\n",
    "wids = [Audio(test_samples[i], rate=22050) for i in e[:5]]\n",
    "for w in wids:\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.nonzero((test_targets != test_predict_pr.argmax(1)) & \\\n",
    "               (test_predict_pr.argmax(1) == 1))[0]\n",
    "\n",
    "wids = [Audio(test_samples[i], rate=22050) for i in e[:5]]\n",
    "for w in wids:\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.nonzero((test_targets != test_predict_pr.argmax(1)) & \\\n",
    "               (test_predict_pr.argmax(1) == 2))[0]\n",
    "\n",
    "wids = [Audio(test_samples[i], rate=22050) for i in e[:5]]\n",
    "for w in wids:\n",
    "    display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отображение результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.rmdir('../cache/imgs/')\n",
    "shutil.rmtree('../cache/imgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('../cache/imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / interval_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (r, t) in enumerate(zip(test_predict_mean.argmax(1), test_targets)):\n",
    "    im_r = np.zeros((32, 64, 3), dtype='uint8')\n",
    "    if r == 0:\n",
    "        im_r[:,:,0] = 255\n",
    "    elif r == 2:\n",
    "        im_r[...,2] = 255\n",
    "    else:\n",
    "        im_r[...,1] = 255\n",
    "        \n",
    "    im_t = np.zeros((32, 64, 3), dtype='uint8')\n",
    "    if t == 0:\n",
    "        im_t[:,:,0] = 255\n",
    "    elif t == 2:\n",
    "        im_t[...,2] = 255\n",
    "    else:\n",
    "        im_t[...,1] = 255\n",
    "        \n",
    "    im = np.vstack((im_r, im_t))\n",
    "    im = Image.fromarray(im)\n",
    "    im.save('../cache/imgs/test_{:04d}.png'.format(i + 2))\n",
    "im.save('../cache/imgs/test_{:04d}.png'.format(0))\n",
    "im.save('../cache/imgs/test_{:04d}.png'.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('ffmpeg -r 10 -i ../cache/imgs/test_%04d.png -i ../audio/lavina_class.m4a -vcodec mpeg4 -y ../cache/a.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ручная корректировка шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_new = test_predict_new.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_predict_new2 = []\n",
    "\n",
    "start = False\n",
    "for t, tn in zip(test_predict_new, np.append(test_predict_new[1:], [1])):\n",
    "    if t == 0 and tn == 0 and not start:\n",
    "        # если встретили 0 и следующий 0 и до этого не началось, включаем начало и доб-ем 0\n",
    "        start = True\n",
    "        test_predict_new2.append(0)\n",
    "    elif t == 0 and tn == 0 and start:\n",
    "        # если встретили 0 и следующий 0 и до этого началось, доб-ем 0 - мы в серии нулей\n",
    "        test_predict_new2.append(0)\n",
    "    elif t == 0 and tn != 0 and not start:\n",
    "        # если встретили 0, а следующий не 0 и до этого не началось, значит шум, не 0 \n",
    "        test_predict_new2.append(1)\n",
    "    elif t == 0 and tn != 0 and start:\n",
    "        # если встретили 0, а след. не 0 и до этого началось, значит 0, но начало в False\n",
    "        start = False\n",
    "        test_predict_new2.append(0)\n",
    "    elif t == 1:\n",
    "        # если встрили 1, добавляем 1\n",
    "        test_predict_new2.append(1)\n",
    "        start = False\n",
    "    else:\n",
    "        print(t, tn, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(test_predict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series.value_counts(test_predict_new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data.values, test_predict_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data.values, test_predict_new2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision поднялся на 0.07, а recall упал лишь на 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отображение результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('../cache/imgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('../cache/imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (r, t) in enumerate(zip(test_predict_new2, test_data.values)):\n",
    "    im_r = np.zeros((32, 64, 3), dtype='uint8')\n",
    "    if r == 0:\n",
    "        im_r[:,:,0] = 255\n",
    "    elif r == 1:\n",
    "        im_r[...,2] = 255\n",
    "    else:\n",
    "        im_r[...,1] = 255\n",
    "        \n",
    "    im_t = np.zeros((32, 64, 3), dtype='uint8')\n",
    "    if t == 0:\n",
    "        im_t[:,:,0] = 255\n",
    "    elif t == 1:\n",
    "        im_t[...,2] = 255\n",
    "    else:\n",
    "        im_t[...,1] = 255\n",
    "        \n",
    "    im = np.vstack((im_r, im_t))\n",
    "    im = Image.fromarray(im)\n",
    "    im.save('../cache/imgs/test_{:04d}.png'.format(i + 2))\n",
    "im.save('../cache/imgs/test_{:04d}.png'.format(0))\n",
    "im.save('../cache/imgs/test_{:04d}.png'.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('ffmpeg -r 20 -i ../cache/imgs/test_%04d.png -i ../audio/arhis1.mp3 -vcodec mpeg4 -y ../cache/aa.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
